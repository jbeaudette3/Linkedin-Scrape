{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scrape/search single 2021.04.16.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOkDTYaMd/I4iwGXo2vVxGE"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpOGJc17Hhyh"
      },
      "source": [
        "url = 'https://www.linkedin.com/jobs/search/?'\n",
        " \n",
        "companyList = []\n",
        "titleList = []\n",
        "locationList = []\n",
        "dateList = []\n",
        "descriptionList = []\n",
        "companyWebsiteList = []\n",
        "companyWebsiteListC = []\n",
        "jobWebsiteList = []\n",
        "jobWebsiteListC = []\n",
        "\n",
        "\n",
        "### Parameters ###\n",
        " \n",
        "# keywords, no more than 5 are allowed\n",
        "listA = ['python', 'sql', 'excel', 'data', 'analyst']\n",
        " \n",
        "# Pages: no more than 20, please\n",
        "p = 5\n",
        " \n",
        "# days to backdate search\n",
        "d = 30\n",
        " \n",
        "# Experience Level (1-6)\n",
        "# 1 = internship    2 = Entry Level   3 = Associate  \n",
        "# 4 = Mid-Senior    5 = Director      6 = Executive \n",
        "level = ['1', '2', '3']\n",
        " \n",
        "# Job Type\n",
        "# F = Full-Time   C = Contract    P = Part-Time\n",
        "# T = Temporary   O = Other\n",
        "jT = ['F']\n",
        " \n",
        "# salary\n",
        "# listed as minimum, always greater than number listed  \n",
        "# 1 = $40k   2 = $60k   3 = $80k\n",
        "# 4 = $100k  5 = $120k  6 = $140k  \n",
        "# 7 = $160k  8 = $180k  9 = $200k  \n",
        "s = 1\n",
        " \n",
        "# sort\n",
        "# sort by most recent - DD\n",
        "# sort by most relevent - R\n",
        "so = '&sortBy=R'\n",
        "\n",
        "l = 'location=Chicago%2C%20Illinois%2C%20United%20States'\n",
        " \n",
        "url2 = (url\n",
        "        + keywords(listA)\n",
        "        + '&'\n",
        "        + daysToSeconds(d)\n",
        "        + '&'\n",
        "        + expLevel(level)\n",
        "        + '&'\n",
        "        + jobType(jT)\n",
        "        + '&'\n",
        "        + l\n",
        "        + '&'\n",
        "        + so\n",
        ")\n",
        "\n",
        "################### CODE RUNS AUTOMATICALLY AFTER THIS ###################\n",
        "##########################################################################\n",
        "\n",
        "# Allows multiple outputs from a single cell:\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        " \n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time as time\n",
        "import random\n",
        "import pprint\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        " \n",
        "pd.set_option(\"display.max_rows\", None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "###################### function definitionS ######################\n",
        "\n",
        "def keywords(l):\n",
        "  \"\"\"\n",
        "  Accepts list of strings to use in keywords.\n",
        "  Accepts single string or multiple.\n",
        "  Ex: keywords(l = ['helpdesk', 'IT'])\n",
        "  \"\"\"\n",
        "  _ = 'keywords='\n",
        "  if len(l) == 1:\n",
        "    return _ + l[0]\n",
        "  else:\n",
        "    return _ + '%20'.join(listA)\n",
        " \n",
        " \n",
        "def daysToSeconds(days = 1):\n",
        "  \"\"\"\n",
        "  Input number of days to backdate search\n",
        "  Returns number of seconds (per URL)\n",
        "  Integers only, please\n",
        "  Ex: daysToSeconds(days = 5)\n",
        "  \"\"\"\n",
        "  s = days * 24 * 60 * 60\n",
        "  return f'f_TPR=r{s:.0f}'\n",
        "\n",
        "dTS = lambda s: 'f_TPR=r' + str(s * 24 * 60 * 60)\n",
        " \n",
        " \n",
        "def expLevel(level = '3'):\n",
        "  \"\"\"\n",
        "  Accepts list of numbers as strings or single number (as string).\n",
        "  Ex: expLevel(level = ['2', '3'])\n",
        "  1 = Internship  \n",
        "  2 = Entry Level  \n",
        "  3 = Associate  \n",
        "  4 = Mid-Senior  \n",
        "  5 = Director  \n",
        "  6 = Executive  \n",
        "  \"\"\"\n",
        "  _ = 'f_E='\n",
        "  if(len(level) == 1):\n",
        "    return _ + level[0]\n",
        "  else:\n",
        "    for i in range(len(level)):\n",
        "      return _ + '%2C'.join(level)\n",
        " \n",
        " \n",
        "def jobType(jobT = 'F'):\n",
        "  \"\"\"\n",
        "  Accepts list of strings.\n",
        "  F = Full-Time\n",
        "  C = Contract\n",
        "  P = Part-Time\n",
        "  T = Temporary\n",
        "  O = Other\n",
        "  Ex: jobType(jobT = ['O', 'F'])\n",
        "  \"\"\"\n",
        "  _ = 'f_JT='\n",
        "  if(len(jobT) == 1):\n",
        "    return _ + jobT[0]\n",
        "  else:\n",
        "    for i in range(len(jobT)):\n",
        "      return _ + '%2C'.join(jobT)\n",
        " \n",
        " \n",
        "def salary(s = 1):\n",
        "  \"\"\"\n",
        "  Listed as minimum, always greater than number listed\n",
        "  Ex: salary(4)\n",
        "  - 1 = $40k  \n",
        "  - 2 = $60k  \n",
        "  - 3 = $80k  \n",
        "  - 4 = $100k  \n",
        "  - 5 = $120k  \n",
        "  - 6 = $140k  \n",
        "  - 7 = $160k  \n",
        "  - 8 = $180k  \n",
        "  - 9 = $200k  \n",
        "  \"\"\"\n",
        "  return 'f_SB2=' + str(s)\n",
        "\n",
        "\n",
        "def scrape(lP, aP):\n",
        "  \"\"\"\n",
        "  Takes length of allPosts, and allPosts.\n",
        "  Uses Requests, Beautiful Soup to scrape from Linkedin\n",
        "  Appends data to arrays\n",
        "  \"\"\"\n",
        "  for i in range(lP):\n",
        "  # company name\n",
        "    companyList.append(aP.find_all('div', {'class':'result-card__contents job-result-card__contents'})[i].find('a',{'class':'result-card__subtitle-link job-result-card__subtitle-link'}).string)\n",
        "  # job website\n",
        "    jobWebsiteList.append(aP.find_all('a', {'class':'result-card__full-card-link'})[i]['href'])       # get website\n",
        "    jobWebsiteListC.append(jobWebsiteList[i][:jobWebsiteList[i].find('?')])                                 # clean website\n",
        "  # title\n",
        "    titleList.append(aP.find_all('a', {'class':'result-card__full-card-link'})[i].find('span', {'class':'screen-reader-text'}).string)\n",
        "  # company website\n",
        "    companyWebsiteList.append(aP.find_all('div', {'class':'result-card__contents job-result-card__contents'})[i].find('a', {'class':'result-card__subtitle-link job-result-card__subtitle-link'})['href'])      # get website\n",
        "    companyWebsiteListC.append(companyWebsiteList[i][:companyWebsiteList[i].find('?')])                                                                                                                               # clean website\n",
        "  # location\n",
        "    locationList.append(aP.find_all('div', {'class':'result-card__contents job-result-card__contents'})[i].find('span',{'class':'job-result-card__location'}).string)\n",
        "  # snippet\n",
        "    descriptionList.append(aP.find_all('div', {'class':'result-card__contents job-result-card__contents'})[i].find('p',{'class':'job-result-card__snippet'}).string)\n",
        "  # post date\n",
        "    try:\n",
        "      dateList.append(aP.find_all('time',{'class':'job-result-card__listdate'})[i]['datetime'])\n",
        "    except:\n",
        "      dateList.append(None)\n",
        "\n",
        "######################################################################\n",
        "######################################################################\n",
        "##########  END FUNCTION DEFINITION, BEGIN ACTUAL SCRAPING  ##########\n",
        "\n",
        "for j in range(p):\n",
        "  print(j)\n",
        "  o = 25 * j\n",
        "  url3 = url2 + '&start=' + str(o)\n",
        "\n",
        "  response = requests.get(url3)\n",
        "  soup = BeautifulSoup(response.text, 'lxml')\n",
        "\n",
        "  allPosts = soup.find_all('ul', {'class':'jobs-search__results-list'})[0]\n",
        "  lenPosts = len(allPosts.find_all('a', {'class':'result-card__full-card-link'}))\n",
        "\n",
        "  if (lenPosts > 0):\n",
        "    scrape(lenPosts, allPosts)\n",
        "\n",
        "  if (p > 1):\n",
        "    time.sleep(random.uniform(15, 20))           # Remember kids, don't spam.\n",
        "\n",
        "# Now that everything is scraped into arrays:\n",
        "\n",
        "data = {'company': companyList,\n",
        "        'title': titleList,\n",
        "        'location': locationList,\n",
        "        'date': dateList,\n",
        "        'description': descriptionList,\n",
        "        'companyWebsiteC': companyWebsiteListC,\n",
        "        'jobWebsiteC': jobWebsiteListC}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print('----------')\n",
        "print('Keywords Searched:')\n",
        "listA\n",
        "print();print()\n",
        "print(f'Results found: {len(df)}')\n",
        "print()\n",
        "print('----------')\n",
        "print()\n",
        "\n",
        "print(df.groupby(['title']).size().sort_values(ascending=False).head(15))\n",
        "print()\n",
        "print(df.groupby(['location']).size().sort_values(ascending=False).head(15))\n",
        "print()\n",
        "print(df.groupby(['company']).size().sort_values(ascending=False).head(20))\n",
        "print()\n",
        "print(df.groupby(['company']).size().sort_values(ascending=True).head(20))\n",
        "print()\n",
        "print('-------------------- Chicago or IL --------------------')\n",
        "try: df.loc[df['location'].str.contains('Chicago') | df['location'].str.contains('IL')].head(20)\n",
        "except: pass\n",
        "print()\n",
        "print('Companies located in Chicago:')\n",
        "try: print(df.loc[df['location'] == 'Chicago, IL']['company'].unique())\n",
        "except: pass\n",
        "print()\n",
        "print('-------------------- Chicago, IL --------------------')\n",
        "try: df.loc[df['location'] == 'Chicago, IL']\n",
        "except: pass\n",
        "print('-------------------- Remote --------------------')\n",
        "try: df.loc[df['title'].str.contains('Remote')].head(20)\n",
        "except: pass\n",
        "\n",
        "########## AT THE END, PRINT FINAL DATAFRAME AND SAVE RESULTS ##########\n",
        "df\n",
        "\n",
        "df.to_csv('/data/job_list.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}